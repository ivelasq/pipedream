{
  "hash": "f430a2390e592778d81652b2fedcde11",
  "result": {
    "markdown": "---\ncategories: [\"import\", \"tidy\", \"visualize\"]\ndate: \"2020-05-28\"\ntitle: \"What it takes to tidy Census data\"\nimage: thumbnail.jpg\ndescription: Census data is valuable, but can be stored in messy Excel spreadsheets.\n---\n\n![Hendrick Avercamp, Ice-skating in a Village (1610)](thumbnail-wide.jpg){fig-alt=\"A town of people skating on a frozen lake\"}\n\nThe U.S. Census releases aggregate data on their [Household Pulse Survey](https://www.census.gov/data/tables/2020/demo/hhp2.html). These data are valuable and cover a range of important topics, particularly those related to the COVID-19 pandemic.\n\nFirst of all, let me clarify that I think that the work that the Census does is amazing and I am so glad that these data are available. But, when you download the data, you will see that it is a highly stylized Excel spreadsheet. There may be upsides for those who want to see the data quickly and easily. As an R user though, seeing all those merged cells, non-numeric numerics, and category names in rows makes me feel `emo::ji('unamused')`.\n\n![](census_image.png){fig-alt=\"One of the Census Excel spreadsheets pointing out egregious formatting, like headers, merged cells, and categories in rows.\"}\n\nHowever, this is not terribly surprising (and with public data, somewhat expected). As stated in the [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) paper:\n\n> It is often said that 80% of data analysis is spent on cleaning and preparing data.\n\nThankfully, we have the very powerful R and tidyverse available to address our data woes. Let's go through the process of tidying these data with tidyverse packages to show how easily they can become ready for analysis!\n\n## Loading the data\n\nAs usual, we begin by loading our packages.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(httr)\n```\n:::\n\nWe have the option to download the Excel file and load it in R. But what if we want to load the data directly from the website? We can use {httr}! The following code 'gets' the file from the internet, writes it in a temporary file path, and loads it in an object called `path`.\n\n> Many thanks to Liz Potamites for pointing out: if the below doesn't work, it may be that the link is changed or broken. It should be Table 2 from the second week of the Household Pulse Survey, which as of July 21, 2020, is located [here](https://www.census.gov/data/tables/2020/demo/hhp/hhp2.html).\n\n::: {.cell}\n\n```{.r .cell-code}\nGET(\"https://www2.census.gov/programs-surveys/demo/tables/hhp/2020/wk2/educ2_week2.xlsx\", write_disk(path <- tempfile(fileext = \".xlsx\")))\n```\n\n::: {.cell-output-stdout}\n```\nResponse [https://www2.census.gov/programs-surveys/demo/tables/hhp/2020/wk2/educ2_week2.xlsx]\n  Date: 2022-03-13 15:45\n  Status: 200\n  Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n  Size: 442 kB\n<ON DISK>  /var/folders/pj/nmg9b8_93dq4kwt8nt2d4cj40000gn/T//RtmpRY4m58/file2eca17a48009.xlsx\n```\n:::\n:::\n\n## Cleaning the data\n\nAs mentioned in the figure above, each sheet comprises a state's data. It'd be good to have all of the data in one single data structure. One option is to try to force all of the sheets together at once in a data frame (which is a 2D structure). But we also saw that each sheet requires a lot of cleaning before it can be useful, and it may be difficult to clean if they're all merged in one data frame. Therefore, let's instead first read in all the data as a **list** (which is a higher dimension structure), clean it up, and *then* put it together in a data frame.\n\nHowever, I am not very good at thinking about things in a list format and it's a little harder to see what's going on compared to looking at a data frame using `View()`. Before I clean up a list, I usually work on a single cut of the list as a data frame to know what exactly I am going to do. Thankfully, all the sheets in this Excel sheet are formatted the same across states. This isn't always the case! Because they are identically formatted, we know if our processing works on one sheet, it will work across all of them.\n\nLet's look at a single sheet!\n\n### Single sheet cleaning\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_sheet1 <-\n  read_excel(path, sheet = 1)\n\nView(census_sheet1)\n```\n:::\n\n![First three columns of the imported dataset](census1.png){fig-alt=\"First three columns of the imported dataset, first column is the table title and the other two don't have names and are listed as dot dot dot 2 and dot dot dot 3.\"}\n\nImmediately, we see that the top lines are superfluous rows (the headers from the original dataset). We can use `skip` in `read_excel()` to not have them read in.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_sheet1 <-\n  read_excel(path, sheet = 1, skip = 3)\n\n# View(census_sheet1)\n```\n:::\n\n![Dataset with skipped lines](census2.png){fig-alt=\"Dataset with skipped lines so that the column names are now characteristics, Total, and impact of the pandemic on children's education.\"}\n\nNow that the unnecessary rows are gone, we see that the column names aren't reading in super well because of the merged cells in the original sheet. In this case, we manually create a vector of the column names and replace the old ones with `set_names()`.\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_names <-\n  c(\"select_characteristics\", \"total\", \"using_online_resources\", \"using_paper_materials_sent_home\", \"where_classes_were_cancelled\", \"where_classes_changed_in_another_way\", \"where_no_change_to_classes\", \"did_not_respond\")\n\ncensus_example <-\n  census_sheet1 %>% \n  set_names(new_names)\n```\n:::\n\n![Dataset with cleaned names](census3.png){fig-alt=\"Dataset with cleaned names so that they are select underscore characteristics, total, and using online resources.\"}\n\nWe still have some empty rows (and also a row at the very bottom which is a note in the original dataset). We can eliminate these rows using `slice()`. Here, we're saying to 'slice' rows 1 through 3 and 60.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_example <-\n  census_example %>% \n  slice(-1:-3, -60:-61)\n```\n:::\n\n![Dataset with removed rows](census4.png){fig-alt=\"Dataset with removed rows so that the first rows start to line up with the columns.\"}\n\nNow to deal with the fact that the category names are embedded within the first column `select_characteristics`. There may be other ways to do this, but again I manually create a vector with all the values that I want to get rid of and use `filter()` to keep only the rows that do **not** contain the items in the vector.\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter_var <- \n  c(\"Age\", \"Sex\", \"Hispanic origin and Race\", \"Education\", \"Marital status\", \"Presence of children under 18 years old\", \"Respondent or household member experienced loss of employment income\", \"Mean weekly hours spent on…\", \"Respondent currently employed\", \"Food sufficiency for households prior to March 13, 2020\", \"Household income\")\n\ncensus_example <-\n  census_example %>% \n  filter(!select_characteristics %in% filter_var) \n```\n:::\n\n![Dataset with filtered rows](census5.png){fig-alt=\"Dataset with filtered rows so that the columns and rows match up.\"}\n\nEven though we removed the characteristic names from the rows, they contain very useful information. Also, we run into an issue in which two of the characteristic categories had the same options (\"yes\" and \"no\"). If we don't address this, we'll forget which rows are for which characteristic. To fix this, we manually create a column with the characteristics for each of the response options and append it to the data.\n\n::: {.cell}\n\n```{.r .cell-code}\ncategory_column <-\n  c(\"age\", \"age\", \"age\", \"age\", \"age\", \"sex\", \"sex\", \"race\", \"race\", \"race\", \"race\", \"race\", \"education\", \"education\", \"education\", \"education\", \"marital_status\", \"marital_status\", \"marital_status\", \"marital_status\", \"marital_status\", \"children\", \"children\", \"loss_employment\", \"loss_employment\", \"loss_employment\", \"hours_spent\", \"hours_spent\", \"employed\", \"employed\", \"employed\", \"food_sufficiency\", \"food_sufficiency\", \"food_sufficiency\", \"food_sufficiency\", \"food_sufficiency\", \"income\", \"income\", \"income\", \"income\", \"income\", \"income\", \"income\", \"income\", \"income\")\n\ncensus_example <-\n  census_example %>% \n  add_column(category_column)\n```\n:::\n\n<center>\n![Column with variable names](census6.png){fig-alt=\"Column with variable names that repeat down the column.\"}\n</center>\n\nFinally, you may have noticed that some of the rows did not read in as numbers but as characters.\n\n<center>\n![Column with numbers but with character type](census7.png){fig-alt=\"Column with numbers but with character type.\"}\n</center>\n\nWe can use `mutate_at()` and specify which variables we want to be numeric.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_example <-\n  census_example %>% \n  mutate_at(vars(total, using_online_resources:did_not_respond), list(~ as.numeric(.)))\n```\n:::\n\nHooray - now we have a tidy dataset we could use for analysis! Which is great, but it's only one sheet. How do we do this for the additional 66?\n\n### Multi-sheet cleaning\n\nWe will now download the data and store it in a list, where each sheet (which represents a state) is saved as a tibble within the list. To work across all the lists, we use the tidyverse package {purrr} and its handy functions.\n\nYou may notice that the multi-sheet cleaning looks a lot like the single sheet cleaning but everything is wrapped in the function `map()`. That's true! The wonderful thing about {purrr} being in the tidyverse is that it's really easy to integrate with all the tidyverse functions.\n\nReading the data into one list is slightly more complicated than reading in a single sheet. We begin with the file path from before and then use `excel_sheets()` to create a vector of the sheet names. `set_names()` ensures that we have a named list that contains the state names, which will be important later. If we don't use `set_names()`, then the tibbles have generic names instead of 'US', 'AL', etc. Then using `purrr::map()`, we ask R to download each of the sheets of the dataset and store it together in a list (`map()` always returns a list).\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_list <-\n  path %>% \n  excel_sheets() %>% \n  set_names() %>% \n  map(~ read_excel(path = path, sheet = .x, skip = 3), .id = \"Sheet\")\n```\n:::\n\nIf you take a look at the list using `View(census_list)`, you can see the data is stored as tibbles within the list. If you expand `US`, you'll see the same data as when we did the single sheet example. You can also see the same data if you run `census_list[[\"US\"]]`.\n\n![Viewing the list](census_list.png){fig-alt=\"Viewing the list of each state with the same data structure underneath\"}\n\nUsing the same thinking as we did with the single sheet example, let's go through and clean up this list - without having to go into each tibble!\n\nFirst, we set the names within each list using `set_names()`. We tell `map()` the names of the columns by defining `nm`.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_list <- \n  census_list %>% \n  map(., set_names, nm = new_names)\n```\n:::\n\nFor each tibble in the list (`.x`), remove the rows 1 through 3 and 60.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_list <- \n  census_list %>% \n  map(~ slice(.x, -1:-3, -60:-61))\n```\n:::\n\nNow for each tibble, filter out the rows in `select_characteristics` that contain the items in `filter_var`.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_list <- \n  census_list %>% \n  map(~ filter(.x, !select_characteristics %in% filter_var))\n```\n:::\n\nLike before, we want a new column that lets us know the category for each of the characteristic options. \n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_list <- \n  census_list %>% \n  map(~ add_column(.x, category_column))\n```\n:::\n\nAnd like before, we want to make sure our numeric columns are actually numeric.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_list <- \n  census_list %>% \n  map(~ mutate_at(.x, vars(total, using_online_resources:did_not_respond), list(~ as.numeric(.))))\n```\n:::\n\nNow that our tibbles are all clean and uniform, let's make this a single, 2D data frame! As I mentioned before, our list should contain the state abbreviations. We can use `map_df()` to create a data frame with an ID column called `state` that stores each of the sheet names. With this column, we'll easily know which column is for which state/geography.\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_df <- \n  census_list %>% \n  map_df(~ as.data.frame(.x), .id = \"state\")\n```\n:::\n\nCongrats! We have successfully tidied a Census dataset!\n\n## Using the data\n\nThe purpose of all this work is to be able to use it easily in R and with the tidyverse specifically. Let's use the plotting package {ggplot2} to make something!\n\nAccording to the Census website, we can calculate percentages by removing those that did not respond from the total for the denominator (let's presume that NA in the column means that everybody responded). Let's say we want to see the proportion of respondents in the U.S. who say their classes were canceled by income level.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncensus_us_income <-\n  census_df %>% \n  filter(state == \"US\", category_column == \"income\") %>% \n  mutate(responses = case_when(!is.na(did_not_respond) ~ total - did_not_respond, \n                               is.na(did_not_respond) ~ total),# calculate denominator\n         pct_cancelled = where_classes_were_cancelled / responses) # calculate percentage\n\ncensus_us_income <- # setting factor levels so graph shows correct order\n  census_us_income %>% \n  mutate(select_characteristics = factor(select_characteristics,\n                                         levels = c(\"Less than $25,000\", \n                                                    \"$25,000 - $34,999\",\n                                                    \"$35,000 - $49,999\",\n                                                    \"$50,000 - $74,999\",\n                                                    \"$75,000 - $99,999\",\n                                                    \"$100,000 - $149,999\",\n                                                    \"$150,000 - $199,999\",\n                                                    \"$200,000 and above\")))\n\ncensus_us_income %>% \n  filter(select_characteristics != \"Did not report\") %>% \n  ggplot(aes(x = select_characteristics, y = pct_cancelled)) +\n  geom_bar(stat = \"identity\",\n           fill = \"#00C3DA\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"Percent of Respondents Whose Children's Classes Were Cancelled\",\n       x = \"Income\",\n       y = \"Percent with Classes Cancelled\",\n       caption = \"Source: U.S. Census\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){fig-align='center' fig-alt='Barplot showing percent of classes that were cancelled by income group, with lower income groups more likely to report cancelled classes' width=672}\n:::\n:::\n\nFrom this graph, we can see that respondents from the lower-income bands were more likely to say that classes were canceled for their children due to COVID.\n\n<center>\n*Liked this article? I’d love for you to retweet!*\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">New blogpost 📣: What It Takes to Tidy Census Aggregate Data! ⭐ Let&#39;s take all those heavily formatted Excel sheets and make them a plain and simple data frame together! <a href=\"https://t.co/IsPb8BJ0ZT\">https://t.co/IsPb8BJ0ZT</a> <a href=\"https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw\">#rstats</a> <a href=\"https://t.co/XABr07wYfP\">pic.twitter.com/XABr07wYfP</a></p>&mdash; Isabella Velásquez (@ivelasq3) <a href=\"https://twitter.com/ivelasq3/status/1266372221179588609?ref_src=twsrc%5Etfw\">May 29, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> \n</center>",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}